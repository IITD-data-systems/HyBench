# HyBench

**HyBench** is a benchmark framework for evaluating **hybrid queries** in vector databases using a MediaWiki-based dataset. It integrates structured and vector data to assess performance on real-world hybrid workloads.

## Requirements

- **FAISS** (libfaiss.a) and OpenBLAS
- **HNSWlib** for C++
- **C++17** with OpenMP support
- **Python 3.6+**
- **HuggingFace transformers** (for benchmark_generator.py)

## Project Structure

The repository is organized into five main directories:

```
HyBench/
â”œâ”€â”€ baseline-implementation/
â”œâ”€â”€ database-generation/
â”œâ”€â”€ output-files/
â”œâ”€â”€ query-generation/
â””â”€â”€ query-templates/
```

### 1. database-generation/

This directory contains all components for generating the benchmark database and embeddings.

#### Subdirectories:

- **`data_csv_files/`** - Contains the core MediaWiki dataset files organized in subdirectories:
  - `category_csv_files/` - Contains `category_links_clean.csv` with columns `cl_from` and `cl_to`
  - `page_csv_files/` - Contains:
    - `page.csv` - Columns: `page_id`, `page_title` (ordered by page_id)
    - `embedding.csv` - Embeddings corresponding to page titles in same order as page.csv
    - `page_extra.csv` - Columns: `page_len`, `page_touched`, `page_namespace` (ordered by page_id)
  - `text_csv_files/` - Contains:
    - `text.csv` - Columns: `old_id`, `old_text` (ordered by old_id)
    - `embedding.csv` - Embeddings for old_text in same order as text.csv
  - `revision_csv_files/` - Contains `revision_clean.csv` with columns: `rev_id`, `rev_page`, `rev_minor_edit`, `rev_actor`, `rev_timestamp`

- **`index_files/`** - C++ implementation files to generate indexes using HNSWlib and FAISS libraries

- **`offsets_files/`** - Code to generate offset files for fast line access in baseline implementation

#### Quick Start:

```bash
cd database-generation
bash database_and_query_generator.sh
```

This script will:
- Generate all embedding files (for page and text)
- Create queries in the query-generation directory
- Build required index and offset files

## Dataset Scaling

To scale the dataset to larger sizes (up to 200Ã— the initial 10M data size):

```bash
cd database-generation
g++ scale_database.cpp -o scale_database -O3 -std=c++17
./scale_database <scale_factor>


#### Customization:

- **Embedding Models**: Check `models_supported.txt` for available models. Modify the first command in `database_and_query_generator.sh` to use a different model (instructions provided in comments inside the sh file)
- **System Configuration**: Update FAISS library paths in compile commands according to your system setup (further instructions in sh file)

### 2. baseline-implementation/

Contains the C++ baseline implementation for query execution.

#### Structure:
- **`queries/`** - C++ implementation of all 39 benchmark queries
  - `runner.cpp` - Main query execution runner
  - `run.sh` - Compilation and execution script

#### Usage:

```bash
cd baseline-implementation/queries
bash run.sh
```

This will compile and run all queries for all combinations of indexes and metrics, outputting query execution times.

**Note**: Update FAISS library paths in `run.sh` according to your system configuration. (further instructions in sh file's comments)

#### Additional Files:
- `pipeline_stages.cpp` - Helper implementations for indexes and utility functions

### 3. query-generation/

Contains generated queries for each of the 39 benchmark queries in the format required by the baseline implementation. These are automatically generated by the database generation script.

### 4. query-templates/

Contains SQL templates for all 39 queries organized by similarity semantic categories:
- Nearest neighbor queries
- Interval-based queries  
- Sampling-based queries

### 5. output-files/

Contains experimental results and analysis tools.

#### Contents:
- **Results directories**:
  - `brute_queries_output/` - Brute force query results
  - `baseline_queries_output/` - Baseline implementation results
  - `pgvector_query_plans/` - PostgreSQL pgvector execution plans
  - `postgres_queries_output/` - PostgreSQL pgvector query results

- **Analysis tools**:
  - `ground_truth_result_computer.py` - Python script for running queries using pgvector with psycopg2 to compute ground truth results
  - `accuracy_baseline.sh` - Accuracy calculation script for baseline implementation
  - `raw_results.xlsx` - Raw experimental results with color-coded performance comparisons

**Note on Ground Truth**: Ground truth is calculated using PostgreSQL with pgvector. The current directories already contain ground truth results for the default experimental setup. However, if you use a different embedding model, you will need to recalculate the ground truth using `ground_truth_result_computer.py`, which requires PostgreSQL and pgvector to be installed and configured on your system. The existing results are provided for the experimented dataset and default embedding model.

#### Accuracy Evaluation:

```bash
cd output-files
bash accuracy_baseline.sh
```

This script calculates accuracy results for all combinations of metrics and indexes for the baseline implementation.

#### Result Interpretation:
The Excel sheet uses color coding:
- ðŸ”´ **Red**: pgvector outperforms baseline
- ðŸ”µ **Blue**: Similar performance
- ðŸŸ¢ **Green**: Baseline outperforms pgvector

## Getting Started

1. **Prepare your MediaWiki dataset** in the required CSV format within `data_csv_files/`
2. **Configure system paths** for FAISS library locations
3. **Generate database and queries**:
   ```bash
   cd database-generation
   bash database_and_query_generator.sh
   ```
4. **Run baseline benchmarks**:
   ```bash
   cd baseline-implementation/queries
   bash run.sh
   ```
5. **Evaluate accuracy**:
   ```bash
   cd output-files
   bash accuracy_baseline.sh
   ```
